{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iksnn/Learn-Basic-Deep-Learning/blob/main/Langchain_Gemini.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Library"
      ],
      "metadata": {
        "id": "U_JlyaNz8nhw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip  install -qq langchain-google-genai google-generativeai"
      ],
      "metadata": {
        "id": "DvKfCFKagxuc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d70e0c41-f1a0-4ae1-a537-cdd360eb591f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Credentials API_Key"
      ],
      "metadata": {
        "id": "Lo4tPoN58rvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "\n",
        "API_KEY = getpass.getpass('Write your API KEY here:')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYkpjfaQ5KjA",
        "outputId": "8a68d9fd-2fa9-4b38-c72e-80ef701f0076"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Write your API KEY here:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Langchain Google Gemini"
      ],
      "metadata": {
        "id": "VQAAEW3FKZC-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Invocation\n"
      ],
      "metadata": {
        "id": "tiIgZfn1NfYH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Writing prompt directly in invoke function"
      ],
      "metadata": {
        "id": "gir3pxx7Phbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    temperature=0.7,\n",
        "    api_key=API_KEY\n",
        "    )\n",
        "llm.invoke(\"hi how are you?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYxwwjrQPgBi",
        "outputId": "6cee6a9d-cc13-4fc6-e652-06a7ba59684d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='I am doing well, thank you for asking!  How are you today?\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-f0e3c84a-49a1-418e-a8d1-93b827ff1125-0', usage_metadata={'input_tokens': 6, 'output_tokens': 17, 'total_tokens': 23, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Writing prompt with system and human prompt with langchain"
      ],
      "metadata": {
        "id": "DXAj9POoPmhn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    api_key=API_KEY,\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    temperature=0.7,\n",
        ")\n",
        "messages = [\n",
        "    (\n",
        "        \"system\",\n",
        "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
        "    ),\n",
        "    (\"human\", \"I love programming.\"),\n",
        "]\n",
        "ai_msg = llm.invoke(messages)\n",
        "ai_msg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G72FEn0-KHy7",
        "outputId": "7be023b8-f391-4775-d9f9-dcfba6230d02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"J'aime la programmation.\\n\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-9d71a9f0-fd47-44b5-bc37-ee2be54258ac-0', usage_metadata={'input_tokens': 21, 'output_tokens': 7, 'total_tokens': 28, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multimodal Input"
      ],
      "metadata": {
        "id": "OQElBvgcTrSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import base64, httpx\n",
        "\n",
        "def encode_image(image_path):\n",
        "  with open(image_path, \"rb\") as image_file:\n",
        "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
        "\n",
        "# Initialize the model\n",
        "model = ChatGoogleGenerativeAI(\n",
        "    api_key=API_KEY,\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    temperature=0.7\n",
        "    )\n",
        "\n",
        "# Download and encode the image\n",
        "image_data = encode_image(\"/content/drive/MyDrive/MSIB Celerates Batch 7/Code Ipynb/44. Introduction to LLM/apple.png\")\n",
        "\n",
        "# Create a message with the image\n",
        "message = HumanMessage(\n",
        "    content=[\n",
        "        {\"type\": \"text\", \"text\": \"describe the fruit in this image\"},\n",
        "        {\n",
        "            \"type\": \"image_url\",\n",
        "            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"},\n",
        "        },\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Invoke the model with the message\n",
        "response = model.invoke([message])\n",
        "\n",
        "# Print the model's response\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNAMzFPdKdMg",
        "outputId": "5f7f998f-330b-4232-87e6-e87deadca3c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image shows three red apples. Two are whole, and one is cut in half, revealing its pale yellow flesh and dark brown seeds.  The apples are a deep red color with some lighter shading, indicating a degree of ripeness.  Fresh green leaves are arranged around the apples. The apples appear to be juicy and crisp.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crjiEnZ8lffY",
        "outputId": "1d1c3b17-dd06-4ba7-8a96-9b3975add120"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='The image shows three red apples. Two are whole, and one is cut in half, revealing its pale yellow flesh and dark brown seeds.  The apples are a deep red color with some lighter shading, indicating a degree of ripeness.  Fresh green leaves are arranged around the apples. The apples appear to be juicy and crisp.\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-a0fed14b-3c62-470c-9e35-b82a6dcec35a-0', usage_metadata={'input_tokens': 265, 'output_tokens': 68, 'total_tokens': 333, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0k_Asnwn5nB3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}